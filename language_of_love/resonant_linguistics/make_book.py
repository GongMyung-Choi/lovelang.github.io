# -*- coding: utf-8 -*-
# ìœ„ì¹˜ ì•„ë¬´ ë° OK. ê¶Œì¥: lovelang.github.io/language_of_love/Resonant_Linguistics/
# ì‹¤í–‰:  python make_book.py
#
# ìë™ ìˆ˜í–‰:
#  1) .docx ì›ê³  ìë™ íƒìƒ‰(í˜„ì¬ í´ë” â†’ ìƒìœ„ë¡œ .git ì°¾ì€ ë’¤ ì €ì¥ì†Œ ì „ì²´ ìŠ¤ìº”; goods/library ë“± í¬í•¨)
#  2) ë³¸ë¬¸ ì¶”ì¶œ â†’ ì¥/ë¶€/ë¡œë§ˆìˆ«ì/ì˜ë¬¸ Chapter/ê´„í˜¸ë²ˆí˜¸/ì—í•„ë¡œê·¸ ìë™ ë¶„í• 
#  3) ch1~chN.xhtml + epilogue.xhtml + index.xhtml + glossary/references/appendix + stylesheet.css ìƒì„±
#  4) images/cover.png ìˆìœ¼ë©´ í‘œì§€ ìë™ í‘œì‹œ
#  5) ì „ë¶€ UTF-8ë¡œ ì €ì¥(ê¸€ì ê¹¨ì§ ë°©ì§€)

import os, re, html, zipfile, time

# ---------------- ê¸°ë³¸ ì„¤ì • ----------------
OUT_DIR = "."
IMG_DIR = os.path.join(OUT_DIR, "images")
CSS_NAME = "stylesheet.css"

# ìš°ì„ ìˆœìœ„ ë†’ì€ í‚¤ì›Œë“œ (íŒŒì¼ëª…ì— í¬í•¨ë˜ë©´ ê°€ì‚°ì )
PREFERRED_KEYWORDS = ["ê°ì‘", "ì–¸ì–´", "ìˆ¨", "ë£¨ì›¨ì¸", "Resonant", "Linguistics", "h_"]

# ---------------- ìœ í‹¸ ----------------
def find_repo_root(start):
    cur = os.path.abspath(start)
    while True:
        if os.path.isdir(os.path.join(cur, ".git")):
            return cur
        up = os.path.dirname(cur)
        if up == cur:  # reached drive root
            return os.path.abspath(start)
        cur = up

def score_docx(path):
    name = os.path.basename(path)
    score = 0
    lower = name.lower()
    for kw in PREFERRED_KEYWORDS:
        if kw.lower() in lower:
            score += 100
    try:
        st = os.stat(path)
        score += int(st.st_size / 1024)  # í¬ê¸° ê°€ì‚° (ëŒ€ìš©ëŸ‰ ì›ê³  ìš°ì„ )
        score += int(st.st_mtime / 86400) % 1000  # ìµœê·¼ ìˆ˜ì • ì•½ê°„ ê°€ì‚°
    except:  # pragma: no cover
        pass
    return score

def find_docx():
    # 1) í˜„ì¬ í´ë” ì§ì ‘ íƒìƒ‰
    here = os.path.abspath(".")
    candidates = [os.path.join(here, f) for f in os.listdir(here) if f.lower().endswith(".docx")]
    if candidates:
        best = max(candidates, key=score_docx)
        return best

    # 2) ì €ì¥ì†Œ ë£¨íŠ¸ íŒŒì•… í›„ ì „ì²´ ìŠ¤ìº”
    root = find_repo_root(here)
    hits = []
    for base, dirs, files in os.walk(root):
        # ì†ë„: node_modules ë“± ë¬´ì‹œ
        bn = os.path.basename(base).lower()
        if bn in (".git", "node_modules", ".venv", "__pycache__"):
            continue
        for f in files:
            if f.lower().endswith(".docx"):
                path = os.path.join(base, f)
                hits.append(path)
    if not hits:
        raise SystemExit("âŒ .docx ì›ê³ ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (í˜„ì¬/ì €ì¥ì†Œ ì „ì²´)")

    # goods/library/ebooksÂ·papersÂ·language_of_love ê²½ë¡œ ê°€ì‚°
    def path_boost(p):
        boost = 0
        pl = p.lower()
        for sub in ["goods/library/ebooks", "goods/library/papers", "language_of_love", "resonant_linguistics"]:
            if sub in pl:
                boost += 200
        return boost

    best = max(hits, key=lambda p: score_docx(p) + path_boost(p))
    return best

def xhtml_head(title):
    return f"""<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="ko">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>{html.escape(title)}</title>
  <link rel="stylesheet" href="{CSS_NAME}" />
</head>
<body>
"""

def xhtml_nav(prev_href, next_href):
    prev_link = f'<a href="{prev_href}">â† ì´ì „</a>' if prev_href else '<span></span>'
    next_link = f'<a href="{next_href}">ë‹¤ìŒ â†’</a>' if next_href else '<span></span>'
    return f"""
  <nav style="text-align:center;margin:20px 0;">
    {prev_link} | <a href="index.xhtml">ëª©ì°¨</a> | {next_link}
  </nav>
"""

def xhtml_tail():
    return "\n</body>\n</html>\n"

def para_html(p):  # ë¶ˆí•„ìš” ê³µë°± ì •ë¦¬
    p = re.sub(r"\s+", " ", p).strip()
    return f"<p>{html.escape(p)}</p>"

# ---------------- DOCX â†’ ë¬¸ë‹¨ ----------------
def read_docx_paragraphs(docx_path):
    with zipfile.ZipFile(docx_path) as z:
        xml = z.read("word/document.xml").decode("utf-8", errors="ignore")
    parts = re.split(r"</w:p>", xml)
    paras = []
    for part in parts:
        texts = re.findall(r"<w:t[^>]*>(.*?)</w:t>", part, flags=re.DOTALL)
        if not texts: 
            continue
        txt = html.unescape("".join(texts))
        txt = txt.replace("\u00ad", "")  # soft hyphen ì œê±°
        txt = txt.replace("\r", " ").replace("\n", " ").strip()
        if txt:
            # í˜ì´ì§€ë²ˆí˜¸/ë¨¸ë¦¬ë§ ë‹¨ìˆœ ì œê±°(ìˆ«ìë§Œ í•œ ì¤„ ë“±)
            if re.fullmatch(r"[0-9ivxlcdmIVXLCDM.\-â€“â€”]+", txt):
                continue
            paras.append(txt)
    # ì—°ì† ì¤‘ë³µ ì œê±°
    out, prev = [], None
    for p in paras:
        if p != prev:
            out.append(p); prev = p
    return out

# ---------------- ì¥/ì—í•„ë¡œê·¸ íƒì§€ ----------------
CHAPTER_PATTERNS = [
    r"^\s*ì œ?\s*\d+\s*ì¥[.\s]",      # "ì œ1ì¥", "1ì¥"
    r"^\s*\d+\s*ë¶€[.\s]",            # "1ë¶€"
    r"^\s*[IVX]{1,6}[.\s]",          # "â… .", "II."
    r"^\s*(?:Chapter|CHAPTER|Ch\.)\s*\d+",
    r"^\s*(?:\(|\[)?\d+(?:\)|\.)\s+",# "(1)", "1."
]
EPI_RE = re.compile(r"(ì„¤ê³„ìì˜\s*ê¸°ë¡|í›„ê¸°|ì—í•„ë¡œê·¸|Epilogue)", re.I)

def detect_slices(paras):
    chap_idx, titles = [], []
    for i, p in enumerate(paras):
        if EPI_RE.search(p):  # ì—í•„ë¡œê·¸ëŠ” ë’¤ì—ì„œ ì²˜ë¦¬
            continue
        for pat in CHAPTER_PATTERNS:
            if re.match(pat, p):
                chap_idx.append(i); titles.append(p.strip()); break

    # ì—í•„ë¡œê·¸ ìœ„ì¹˜
    epi_idx = None
    for i, p in enumerate(paras):
        if EPI_RE.search(p):
            epi_idx = i; break

    slices = []
    if chap_idx:
        for k, start in enumerate(chap_idx):
            end = chap_idx[k+1] if k+1 < len(chap_idx) else (epi_idx if (epi_idx and epi_idx>start) else len(paras))
            slices.append((start, end))
    else:
        slices = [(0, epi_idx if epi_idx else len(paras))]
        titles = ["1ì¥"]
    return slices, titles, epi_idx

# ---------------- íŒŒì¼ ìƒì„± ----------------
def ensure_css():
    if os.path.exists(os.path.join(OUT_DIR, CSS_NAME)):
        return
    css = """body{margin:0;font-family:'Noto Sans KR',sans-serif;line-height:1.8;background:#fcfcfc;color:#222;}
main{max-width:820px;margin:40px auto;padding:0 20px;}
h1,h2,h3{color:#004d60;}
nav{text-align:center;margin:20px 0;}
a{color:#006678;text-decoration:none}
a:hover{text-decoration:underline}
"""
    with open(os.path.join(OUT_DIR, CSS_NAME), "w", encoding="utf-8") as f:
        f.write(css)

def write_chapters(paras, slices, titles):
    made = []
    for ci, (start, end) in enumerate(slices, start=1):
        title = titles[ci-1] if ci-1 < len(titles) else f"{ci}ì¥"
        fname = f"ch{ci}.xhtml"
        prev_href = f"ch{ci-1}.xhtml" if ci>1 else None
        next_href = f"ch{ci+1}.xhtml" if ci < len(slices) else ("epilogue.xhtml" if any("ì—í•„ë¡œê·¸" in t or "ì„¤ê³„ìì˜" in t for _,t in made) or True else None)
        body = "\n".join(para_html(p) for p in paras[start:end])
        html_doc = (
            xhtml_head(title)
            + xhtml_nav(prev_href, next_href)
            + f"<main>\n<h1>{html.escape(title)}</h1>\n{body}\n</main>"
            + xhtml_nav(prev_href, next_href)
            + xhtml_tail()
        )
        with open(os.path.join(OUT_DIR, fname), "w", encoding="utf-8") as f:
            f.write(html_doc)
        made.append((fname, title))
    return made

def write_epilogue(paras, epi_idx, last_ch_name):
    if epi_idx is None:
        return False
    epi_body = "\n".join(para_html(p) for p in paras[epi_idx:])
    html_doc = (
        xhtml_head("ì„¤ê³„ìì˜ ê¸°ë¡")
        + xhtml_nav(last_ch_name, None)
        + f"<main>\n<h1>ì„¤ê³„ìì˜ ê¸°ë¡</h1>\n{epi_body}\n</main>"
        + xhtml_nav(last_ch_name, None)
        + xhtml_tail()
    )
    with open(os.path.join(OUT_DIR, "epilogue.xhtml"), "w", encoding="utf-8") as f:
        f.write(html_doc)
    return True

def write_misc_pages():
    for name, title in [("glossary.xhtml","ìš©ì–´ì§‘"),("references.xhtml","ì°¸ê³ ë¬¸í—Œ"),("appendix.xhtml","ë¶€ë¡")]:
        doc = xhtml_head(title) + f"<main><h1>{title}</h1><p>ì¶”í›„ ë‚´ìš© ì¶”ê°€.</p></main>" + xhtml_tail()
        with open(os.path.join(OUT_DIR, name), "w", encoding="utf-8") as f:
            f.write(doc)

def index_has_cover():
    return os.path.exists(os.path.join(IMG_DIR, "cover.png"))

def write_index(toc_list):
    os.makedirs(IMG_DIR, exist_ok=True)
    cover = '<img src="images/cover.png" alt="ê°ì‘ ì–¸ì–´í•™ í‘œì§€" />' if index_has_cover() else ''
    toc_items = "\n".join([f'<li><a href="{f}">{html.escape(t)}</a></li>' for f,t in toc_list])
    if os.path.exists(os.path.join(OUT_DIR, "epilogue.xhtml")):
        toc_items += '\n<li><a href="epilogue.xhtml">ì„¤ê³„ìì˜ ê¸°ë¡</a></li>'
    toc_items += '\n<li><a href="glossary.xhtml">ìš©ì–´ì§‘</a></li>\n<li><a href="references.xhtml">ì°¸ê³ ë¬¸í—Œ</a></li>\n<li><a href="appendix.xhtml">ë¶€ë¡</a></li>'
    doc = f"""<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="ko">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>ğŸŒ€ ê°ì‘ ì–¸ì–´í•™ | Resonant Linguistics</title>
  <link rel="stylesheet" href="{CSS_NAME}" />
  <style>
    .cover{{min-height:60vh;display:flex;flex-direction:column;align-items:center;justify-content:center;text-align:center;gap:16px;background:#f5f7f8;padding:24px}}
    .cover img{{max-width:280px;height:auto;border-radius:8px;box-shadow:0 10px 30px rgba(0,0,0,.08)}}
    .toc{{max-width:820px;margin:30px auto;padding:0 20px}}
    .toc ol{{line-height:1.9}}
    .btn{{display:inline-block;padding:12px 18px;border-radius:8px;border:1px solid #0a6;cursor:pointer;text-decoration:none;color:#0a6}}
  </style>
</head>
<body>
  <header class="cover">
    {cover}
    <h1>ğŸŒ€ ê°ì‘ ì–¸ì–´í•™</h1>
    <p>ì–¸ì–´ëŠ” ì—¬ì „íˆ ìˆ¨ ì‰¬ê³  ìˆë‹¤ â€” ê·¸ ìš¸ë¦¼ì˜ íšŒë¡œë¥¼ ì°¾ì•„ì„œ.</p>
    <p><a class="btn" href="{toc_list[0][0] if toc_list else '#'}">ì½ê¸° ì‹œì‘í•˜ê¸°</a></p>
  </header>
  <main class="toc">
    <h2>ëª©ì°¨</h2>
    <ol>
      {toc_items}
    </ol>
  </main>
</body>
</html>
"""
    with open(os.path.join(OUT_DIR, "index.xhtml"), "w", encoding="utf-8") as f:
        f.write(doc)

# ---------------- ë©”ì¸ ----------------
def main():
    os.makedirs(IMG_DIR, exist_ok=True)
    # 1. ì›ê³  ìë™ íƒìƒ‰
    docx_path = find_docx()
    print(f"ğŸ“„ ì›ê³ : {docx_path}")

    # 2. ë³¸ë¬¸ ë¬¸ë‹¨ ì¶”ì¶œ
    paras = read_docx_paragraphs(docx_path)
    if not paras:
        raise SystemExit("âŒ ë³¸ë¬¸ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë¹ˆ ë¬¸ì„œ?)")

    # 3. ì¥/ì—í•„ë¡œê·¸ ê²½ê³„ ì¡ê¸°
    slices, titles, epi_idx = detect_slices(paras)

    # 4. ì¶œë ¥ ìƒì„±
    ensure_css()
    chapters = write_chapters(paras, slices, titles)
    write_epilogue(paras, epi_idx, chapters[-1][0] if chapters else None)
    write_misc_pages()
    write_index(chapters)

    print("âœ… ì™„ë£Œ:", ", ".join(f for f,_ in chapters), "+ epilogue.xhtml, index.xhtml, stylesheet.css")

if __name__ == "__main__":
    main()
